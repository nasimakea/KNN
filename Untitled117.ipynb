{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V02aHOCqLVC2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. What is the KNN algorithm?"
      ],
      "metadata": {
        "id": "_TWuObvILX8h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yDG_B8DsLYx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "\n",
        "- The K-Nearest Neighbors (KNN) algorithm is a simple yet effective supervised learning algorithm used for both classification and regression tasks. It's a non-parametric, lazy learning algorithm, meaning it doesn't make assumptions about the underlying data distribution and doesn't learn a model during training. Instead, KNN makes predictions based on the similarity of input data points to labeled data points in the training set.\n",
        "\n",
        "    - Here's how the KNN algorithm works:\n",
        "\n",
        "      -Training Phase:\n",
        "\n",
        "        -Store all the labeled data points in memory.\n",
        "      -  Prediction Phase:\n",
        "\n",
        "        - Given a new, unlabeled data point, the algorithm calculates the distance between this point and all other points in the training set. Common distance metrics include Euclidean distance, Manhattan distance, and Minkowski distance.\n",
        "     - It then identifies the K nearest data points (neighbors) based on the calculated distances.\n",
        "     - For classification tasks, KNN assigns the class label that is most frequent among the K neighbors to the new data point.\n",
        "     - For regression tasks, KNN calculates the average (or weighted average) of the target values of the K nearest neighbors and assigns this value to the new data point.\n",
        "Key parameters of the KNN algorithm include:\n",
        "\n",
        "   - K: The number of neighbors to consider. A higher K means smoother decision boundaries but can lead to overfitting, while a lower K can increase sensitivity to noise.\n",
        "-    Distance Metric: The measure used to calculate the distance between data points, such as Euclidean distance, Manhattan distance, etc.\n",
        "KNN is easy to understand and implement, making it a popular choice for introductory machine learning tasks. However, its performance can be sensitive to the choice of K and the distance metric, and it can be computationally expensive for large datasets since it requires calculating distances to all training points for each prediction"
      ],
      "metadata": {
        "id": "PJZrhjBDMGOA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UAHL4WHzMfe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. How do you choose the value of K in KNN?"
      ],
      "metadata": {
        "id": "erffLGS0NDyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "\n",
        "# Choosing the value of K in the K-Nearest Neighbors (KNN) algorithm is a critical step that can significantly impact the model's performance. The choice of K determines the model's bias-variance trade-off, where smaller K values lead to low bias but high variance (more sensitive to noise), and larger K values lead to higher bias but lower variance (smoother decision boundaries).\n",
        "\n",
        "- Here are some common methods to choose the value of K in KNN:\n",
        "\n",
        "# Cross-Validation:\n",
        "\n",
        "- Use techniques like k-fold cross-validation to evaluate the model's performance for different K values.\n",
        "Split the training data into training and validation sets. Train the model using various K values on the training set and evaluate their performance on the validation set.\n",
        "Choose the K value that results in the best performance metrics (e.g., accuracy, F1 score, RMSE for regression) on the validation set.\n",
        "# Grid Search:\n",
        "\n",
        "- Perform a grid search over a range of K values to find the optimal K value.\n",
        "Define a range of K values to explore (e.g., from 1 to a maximum value or using logarithmic spacing).\n",
        "Train and evaluate the model for each K value using cross-validation or a separate validation set.\n",
        "Select the K value that yields the best performance metric.\n",
        "# Rule of Thumb:\n",
        "\n",
        "- A common rule of thumb is to choose K as the square root of the number of data points in the training set.\n",
        "For smaller datasets, a smaller K (e.g., K=3 or K=5) may work well, while for larger datasets, a larger K may be appropriate.\n",
        "# Domain Knowledge:\n",
        "\n",
        "- Consider domain knowledge and the specific characteristics of your dataset.\n",
        "For example, if the classes are well-separated and noise is minimal, a smaller K may suffice. Conversely, in noisy or overlapping classes, a larger K may be more suitable.\n",
        "# Visualizations:\n",
        "\n",
        "- Visualize the decision boundaries for different K values to understand how they affect the model's behavior.\n",
        "Plotting the training data and decision boundaries can provide insights into the optimal K value for your dataset."
      ],
      "metadata": {
        "id": "_j3R9N8TNECi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. What is the difference between KNN classifier and KNN regressor?"
      ],
      "metadata": {
        "id": "uJyADpsuN0Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dj4hplPdNUiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "- The main difference between the K-Nearest Neighbors (KNN) classifier and KNN regressor lies in their task types:\n",
        "\n",
        "# KNN Classifier:\n",
        "\n",
        "- Task: Classification, where the goal is to predict the class label of a new data point based on the majority class of its K nearest neighbors.\n",
        "Output: Discrete class labels (e.g., categories, classes).\n",
        "Example: Predicting whether an email is spam or not spam based on features like sender, subject, and content.\n",
        "# KNN Regressor:\n",
        "\n",
        "- Task: Regression, where the goal is to predict a continuous target variable (numeric value) for a new data point based on the average (or weighted average) of its K nearest neighbors' target values.\n",
        "Output: Continuous numeric values.\n",
        "Example: Predicting the price of a house based on features like size, location, and number of rooms."
      ],
      "metadata": {
        "id": "kFi-j37xN52V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier , KNeighborsRegressor\n",
        "from sklearn.metrics import accuracy_score , mean_squared_error"
      ],
      "metadata": {
        "id": "vSUz9MMZOOlp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris=load_iris()"
      ],
      "metadata": {
        "id": "VWHgxzEPPFDD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVye4fC6PH3d",
        "outputId": "c545c292-069f-495a-951d-0bba6e6b34f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris.feature_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPg0OpqwPJPw",
        "outputId": "b8174efb-b9a3-454e-9539-ab8a40a7ae1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A7gC6DZPMEc",
        "outputId": "7d32a6d9-e275-4183-9e0f-28fddeffc5e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDJ8hXcAPN-a",
        "outputId": "e15edde0-af4c-41e5-a738-0fd26cf60ba8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_cf=iris.data\n",
        "y_cf=iris.target"
      ],
      "metadata": {
        "id": "SOkNIStJPR7W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_cf_train,x_cf_test,y_cf_train,y_cf_test=train_test_split(x_cf,y_cf,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "Okthpe82Pg6H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_cf=KNeighborsClassifier(n_neighbors=3)"
      ],
      "metadata": {
        "id": "dKobP6iIPv-1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_cf.fit(x_cf_train,y_cf_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "o3v_SdgyP52z",
        "outputId": "0836e111-9859-4e1a-ae23-cbc0d0df4083"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_cf_pred=knn_cf.predict(x_cf_test)"
      ],
      "metadata": {
        "id": "kFHe8f03P-0R"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The accuracy score is {accuracy_score(y_cf_pred,y_cf_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rfoU4BjQEIv",
        "outputId": "059e132e-4dc7-48dd-c610-59cef43edc9e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score is 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ncSfpAPGQO0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's see Regression example with boston data"
      ],
      "metadata": {
        "id": "tA0Ire-CQR03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]"
      ],
      "metadata": {
        "id": "AiG6na8WQZRA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_reg,y_reg=data,target"
      ],
      "metadata": {
        "id": "bSpgdyJzQfm-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_reg_train,x_reg_test,y_reg_train,y_reg_test=train_test_split(x_reg,y_reg,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "t_zC_meRQuNn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_reg=KNeighborsRegressor(n_neighbors=5)\n"
      ],
      "metadata": {
        "id": "cKc92puqQ_dl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_reg.fit(x_reg_train,y_reg_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Qw23Ym6DRS8s",
        "outputId": "0cee0c97-54fa-474f-a11a-0fb650c302aa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsRegressor()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_reg_pred=knn_reg.predict(x_reg_test)"
      ],
      "metadata": {
        "id": "YwU3t1v4RbWe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"my mean squared error is {mean_squared_error(y_reg_pred,y_reg_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC6UToiURg2B",
        "outputId": "f288bed7-ecb8-47e5-ad35-9633903de1ec"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my mean squared error is 25.860125490196076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jDYky3I5RrUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4. How do you measure the performance of KNN?"
      ],
      "metadata": {
        "id": "LGh6KxbkRw8S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a0tEFOK5RyBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "\n",
        "\n",
        "#To measure the performance of the K-Nearest Neighbors (KNN) algorithm, you can use evaluation metrics such as accuracy, precision, recall, F1 score (for classification tasks), and mean squared error (MSE) or R-squared (for regression tasks). I'll provide you with a code example using a real dataset to demonstrate how to measure the performance of KNN for a classification task.\n",
        "\n",
        "- Let's use the Iris dataset from scikit-learn, which is a popular dataset for classification tasks. We'll split the dataset into training and testing sets, train a KNN classifier, and then evaluate its performance using accuracy as the evaluation metric."
      ],
      "metadata": {
        "id": "BaOK3xb7SBo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "DRbPhQTiSIrC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "KY5gPZs8SL2R"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "L39CBpUcSN7q"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)"
      ],
      "metadata": {
        "id": "noy3IPHhSQfO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "IkqK7AFmSTEj",
        "outputId": "36d373ba-4342-4c73-a354-1a71e702c796"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = knn.predict(X_test)"
      ],
      "metadata": {
        "id": "5LO9bK32SVBR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kon-jvo9SXqX",
        "outputId": "4ec532db-1ad7-41f2-82b5-b0caceb39033"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fw4VisuRSdkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. What is the curse of dimensionality in KNN?"
      ],
      "metadata": {
        "id": "-3Pxkb3ESpDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r6VtD2_hSqJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "\n",
        "- The curse of dimensionality refers to the challenges and issues that arise when working with high-dimensional data, particularly in machine learning algorithms like K-Nearest Neighbors (KNN). As the number of dimensions (features) in the dataset increases, several problems emerge, impacting the performance and computational efficiency of algorithms like KNN. Here are some key aspects of the curse of dimensionality in relation to KNN:\n",
        "\n",
        "  - Increased Sparsity:\n",
        "\n",
        "In high-dimensional spaces, data points tend to become increasingly sparse, meaning there is more empty space between data points.\n",
        "This sparsity can lead to difficulties in accurately measuring distances between data points, as the concept of proximity becomes less meaningful in sparse spaces.\n",
        "  - Increased Computational Complexity:\n",
        "\n",
        "As the number of dimensions grows, the computational complexity of calculating distances between data points increases significantly.\n",
        "KNN involves calculating the distance between a new data point and all existing data points in the dataset. In high-dimensional spaces, this computation becomes computationally expensive.\n",
        "  - Diminishing Discriminative Power:\n",
        "\n",
        "High-dimensional data can lead to diminishing discriminative power, where the relevance and importance of individual features may decrease.\n",
        "Irrelevant or noisy features can adversely affect the performance of KNN by introducing additional distances that are not meaningful for classification or regression tasks.\n",
        "   - Overfitting:\n",
        "\n",
        "With high-dimensional data, there is a risk of overfitting, where the model may capture noise or irrelevant patterns in the data that do not generalize well to new, unseen data.\n",
        "KNN can be susceptible to overfitting in high-dimensional spaces if the value of K is too small, leading to overly complex decision boundaries.\n",
        "  - Data Sparsity Issues:\n",
        "\n",
        "High-dimensional data often suffers from data sparsity, where the number of samples per unit volume decreases as the number of dimensions increases.\n",
        "This sparsity can result in challenges such as the concentration of data points near boundaries or the presence of outliers that disproportionately affect the model's behavior."
      ],
      "metadata": {
        "id": "epapgMOkSxwo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yjxLIgbrTAvb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}